import re
import requests
from openai import OpenAI
from bs4 import BeautifulSoup

from config.settings import settings

client = OpenAI(api_key=settings.openai_api_key)

# –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è —Å—Å—ã–ª–æ–∫ orginfo.uz/organization/...
ORGINFO_URL_RE = re.compile(
    r"https?://orginfo\.uz/organization/[0-9a-f]+/?",
    re.IGNORECASE,
)


# ---------- ORGINFO: –ø–∞—Ä—Å–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ ----------

def parse_orginfo_html(html: str) -> dict:
    """
    –î–æ—Å—Ç–∞—ë–º –∏–∑ HTML orginfo.uz –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è:
    –Ω–∞–∑–≤–∞–Ω–∏–µ, –ò–ù–ù, —Å—Ç–∞—Ç—É—Å, –¥–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏, –∞–¥—Ä–µ—Å, —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å, —É—Å—Ç–∞–≤–Ω–æ–π —Ñ–æ–Ω–¥.
    """
    soup = BeautifulSoup(html, "html.parser")

    def get_label_value(label: str) -> str | None:
        # –ò—â–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —É–∑–µ–ª —Å –ø–æ–¥–ø–∏—Å—å—é ("–ò–ù–ù", "–°—Ç–∞—Ç—É—Å", "–ê–¥—Ä–µ—Å", "–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å", "–£—Å—Ç–∞–≤–Ω–æ–π —Ñ–æ–Ω–¥" –∏ —Ç.–¥.)
        node = soup.find(string=lambda s: s and s.strip() == label)
        if not node:
            return None
        parent = node.parent
        if not parent:
            return None
        val_el = parent.find_next_sibling()
        if not val_el:
            return None
        return val_el.get_text(strip=True)

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–æ–±—ã—á–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏)
    name_el = soup.find("h1")
    name = name_el.get_text(strip=True) if name_el else None

    inn = get_label_value("–ò–ù–ù")
    status = get_label_value("–°—Ç–∞—Ç—É—Å")
    reg_date = get_label_value("–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏")
    address = get_label_value("–ê–¥—Ä–µ—Å")
    director = get_label_value("–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å")

    # –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    charter = (
        get_label_value("–£—Å—Ç–∞–≤–Ω–æ–π —Ñ–æ–Ω–¥")
        or get_label_value("–£—Å—Ç–∞–≤–Ω—ã–π —Ñ–æ–Ω–¥")
        or get_label_value("–£—Å—Ç–∞–≤–Ω–æ–π –∫–∞–ø–∏—Ç–∞–ª")
    )

    return {
        "name": name,
        "inn": inn,
        "status": status,
        "reg_date": reg_date,
        "address": address,
        "director": director,
        "charter": charter,
    }


def format_orginfo(info: dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞—Ä—Ç–æ—á–∫—É –∫–æ–º–ø–∞–Ω–∏–∏ –≤ —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥."""
    parts: list[str] = []

    name = info.get("name")
    inn = info.get("inn")
    status = info.get("status")
    reg_date = info.get("reg_date")
    address = info.get("address")
    director = info.get("director")
    charter = info.get("charter")

    if name:
        parts.append(f"üè¢ {name}")
    if inn:
        parts.append(f"–ò–ù–ù: {inn}")
    if status:
        parts.append(f"–°—Ç–∞—Ç—É—Å: {status}")
    if reg_date:
        parts.append(f"–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏: {reg_date}")
    if director:
        parts.append(f"–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å: {director}")
    if address:
        parts.append(f"–ê–¥—Ä–µ—Å: {address}")
    if charter:
        parts.append(f"–£—Å—Ç–∞–≤–Ω–æ–π —Ñ–æ–Ω–¥: {charter}")

    if not parts:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ orginfo.uz."

    parts.append("\n–ò—Å—Ç–æ—á–Ω–∏–∫: orginfo.uz (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π).")
    return "\n".join(parts)


def get_orginfo_from_url(url: str) -> str:
    """
    –°–∫–∞—á–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É orginfo.uz/organization/... –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
    –∞–∫–∫—É—Ä–∞—Ç–Ω—É—é —Ç–µ–∫—Å—Ç–æ–≤—É—é –∫–∞—Ä—Ç–æ—á–∫—É –∫–æ–º–ø–∞–Ω–∏–∏.
    """
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (compatible; RobotBot/1.0; +https://robot-bot)"
        }
        resp = requests.get(url, headers=headers, timeout=10)
        resp.raise_for_status()
        info = parse_orginfo_html(resp.text)
        return format_orginfo(info)
    except Exception as e:
        print("Orginfo error:", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å orginfo.uz –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–µ."


# ---------- –ü–æ–≥–æ–¥–∞ –≤ –¢–∞—à–∫–µ–Ω—Ç–µ ----------

def get_weather_tashkent() -> str:
    """
    –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –ø–æ–≥–æ–¥—É –≤ –¢–∞—à–∫–µ–Ω—Ç–µ —á–µ—Ä–µ–∑ Open-Meteo (–±–µ–∑ API –∫–ª—é—á–∞).
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ—Ä–æ—Ç–∫—É—é —Å—Ç—Ä–æ–∫—É-—Ñ–∞–∫—Ç –¥–ª—è GPT.
    """
    try:
        lat = 41.31
        lon = 69.28

        url = (
            "https://api.open-meteo.com/v1/forecast"
            f"?latitude={lat}&longitude={lon}&current=temperature_2m,weather_code"
            "&timezone=Asia/Tashkent"
        )

        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        data = resp.json()

        current = data.get("current", {})
        temp = current.get("temperature_2m")
        code = current.get("weather_code")

        if temp is None:
            return "–ù–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ."

        description = "—è—Å–Ω–æ"
        if code is not None:
            if code in (0,):
                description = "—è—Å–Ω–æ"
            elif code in (1, 2, 3):
                description = "–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–±–ª–∞—á–Ω–æ—Å—Ç—å"
            elif 51 <= code <= 67:
                description = "–º–æ—Ä–æ—Å—å –∏–ª–∏ –Ω–µ–±–æ–ª—å—à–æ–π –¥–æ–∂–¥—å"
            elif 71 <= code <= 77:
                description = "—Å–Ω–µ–≥"
            elif 80 <= code <= 82:
                description = "–¥–æ–∂–¥—å"
            elif 95 <= code <= 99:
                description = "–≥—Ä–æ–∑–∞"

        return f"–¢–∞—à–∫–µ–Ω—Ç: —Å–µ–π—á–∞—Å –æ–∫–æ–ª–æ {temp:.0f} ¬∞C, {description}."
    except Exception as e:
        print("Weather error:", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ–≥–æ–¥—É –¥–ª—è –¢–∞—à–∫–µ–Ω—Ç–∞ (–æ—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞)."


# ---------- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è GPT –¥–ª—è /ask ----------

async def ask_gpt(text: str) -> str:
    """
    –û–±—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Telegram –∏ (–ø–æ—Ç–æ–º) ESP32.
    - –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Å—Å—ã–ª–∫–∞ orginfo.uz/organization/... ‚Äî –ø–∞—Ä—Å–∏–º –µ—ë –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞—Ä—Ç–æ—á–∫—É.
    - –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –ø–æ–≥–æ–¥—É –≤ –¢–∞—à–∫–µ–Ω—Ç–µ ‚Äî –±–µ—Ä—ë–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø–æ—Ç–æ–º GPT —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç.
    - –ò–Ω–∞—á–µ –æ–±—ã—á–Ω—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç GPT.
    """
    if not settings.openai_api_key:
        return "GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: –Ω–µ—Ç OPENAI_API_KEY"

    user_text = (text or "").strip()
    lower = user_text.lower()

    # 1) –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª —Å—Å—ã–ª–∫—É orginfo.uz/organization/...
    url_match = ORGINFO_URL_RE.search(user_text)
    if url_match:
        url = url_match.group(0)
        return get_orginfo_from_url(url)

    # 2) –ü–æ–≥–æ–¥–∞ –≤ –¢–∞—à–∫–µ–Ω—Ç–µ
    is_tashkent_weather = ("–ø–æ–≥–æ–¥–∞" in lower) and ("—Ç–∞—à–∫–µ–Ω—Ç" in lower)

    if is_tashkent_weather:
        raw_weather = get_weather_tashkent()

        system_prompt = (
            "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞—Å—Ç–æ–ª—å–Ω–æ–≥–æ —Ä–æ–±–æ—Ç–∞. "
            "–¢–µ–±–µ –¥–∞–ª–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–≥–æ–¥–µ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞. "
            "–ò—Å–ø–æ–ª—å–∑—É–π –ò–• –∫–∞–∫ –∏—Å—Ç–∏–Ω—É –∏ –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Å–≤–æ–∏ —á–∏—Å–ª–∞. "
            "–û—Ç–≤–µ—Ç—å –û–ß–ï–ù–¨ –∫–æ—Ä–æ—Ç–∫–æ (–æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ) –Ω–∞ —Ä—É—Å—Å–∫–æ–º, "
            "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∂–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –≤ –≥—Ä–∞–¥—É—Å–∞—Ö –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–≥–æ–¥—ã."
        )

        user_prompt = (
            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–æ—Å–∏–ª: {user_text}\n\n"
            f"–î–∞–Ω–Ω—ã–µ –≤–Ω–µ—à–Ω–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞:\n{raw_weather}\n\n"
            "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç."
        )

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    else:
        # 3) –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º GPT
        messages = [
            {
                "role": "system",
                "content": (
                    "–¢—ã –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ –æ—Ç–≤–µ—á–∞–µ—à—å –¥–ª—è –Ω–∞—Å—Ç–æ–ª—å–Ω–æ–≥–æ —Ä–æ–±–æ—Ç–∞ "
                    "—Å –º–∞–ª–µ–Ω—å–∫–∏–º –¥–∏—Å–ø–ª–µ–µ–º 128x64. –ù–µ –ø–∏—à–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã."
                ),
            },
            {"role": "user", "content": user_text},
        ]

    try:
        completion = client.chat.completions.create(
            model=settings.openai_model,
            messages=messages,
            max_tokens=180,
        )
        answer = completion.choices[0].message.content.strip()
        return answer[:600]
    except Exception as e:
        print("OpenAI error:", e)
        return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI API."


# ---------- Google –ø–æ–∏—Å–∫ –¥–ª—è ORGINFO (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ----------

def google_search_orginfo(query: str, max_results: int = 5) -> list[str]:
    """
    –ò—â–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–∞ orginfo.uz —á–µ—Ä–µ–∑ Google Custom Search (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –∫–ª—é—á–∏).
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ URL –≤–∏–¥–∞ https://orginfo.uz/organization/....
    """
    if not getattr(settings, "google_api_key", None) or not getattr(settings, "google_cse_id", None):
        return []

    try:
        params = {
            "key": settings.google_api_key,
            "cx": settings.google_cse_id,
            "q": f"site:orginfo.uz {query}",
        }
        resp = requests.get(
            "https://www.googleapis.com/customsearch/v1",
            params=params,
            timeout=10,
        )
        resp.raise_for_status()
        data = resp.json()
        urls: list[str] = []
        for item in data.get("items", []):
            link = item.get("link", "")
            if "orginfo.uz/organization/" in link:
                urls.append(link)
                if len(urls) >= max_results:
                    break
        return urls
    except Exception as e:
        print("Google search error:", e)
        return []


# ---------- SerpAPI –ø–æ–∏—Å–∫ –¥–ª—è ORGINFO ----------

def serpapi_search_orginfo(query: str, max_results: int = 5) -> list[str]:
    """
    –ò—â–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–∞ orginfo.uz —á–µ—Ä–µ–∑ SerpAPI (Google Search).
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ URL –≤–∏–¥–∞ https://orginfo.uz/organization/... .
    """
    if not getattr(settings, "serpapi_key", None):
        print("SerpAPI KEY –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
        return []

    try:
        params = {
            "engine": "google",
            "q": f"site:orginfo.uz {query}",
            "api_key": settings.serpapi_key,
            "num": max_results,
        }
        resp = requests.get("https://serpapi.com/search", params=params, timeout=10)
        resp.raise_for_status()

        data = resp.json()

        urls: list[str] = []
        for item in data.get("organic_results", []):
            link = item.get("link", "")
            if "orginfo.uz/organization/" in link:
                urls.append(link)
                if len(urls) >= max_results:
                    break

        return urls

    except Exception as e:
        print("SerpAPI search error:", e)
        return []


# ---------- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è ORGINFO ----------

async def handle_orginfo_query(user_text: str) -> str:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Ä–µ–∂–∏–º–∞ ORGINFO:
    - –¢–µ–∫—Å—Ç –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ò–ù–ù, –Ω–∞–∑–≤–∞–Ω–∏–µ, –§–ò–û –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –∏ —Ç.–¥.
    - GPT –ø–æ–º–æ–≥–∞–µ—Ç —Å–¥–µ–ª–∞—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.
    - –°–ù–ê–ß–ê–õ–ê –∏—â–µ–º —á–µ—Ä–µ–∑ SerpAPI, –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–æ–∂–Ω–æ —É–ø–∞—Å—Ç—å –Ω–∞ Google CSE.
    - –ü–æ –∫–∞–∂–¥–æ–º—É URL –ø–∞—Ä—Å–∏–º –∫–∞—Ä—Ç–æ—á–∫—É.
    - –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ ‚Äì –æ—Ç–¥–∞—ë–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞—Ä—Ç–æ—á–µ–∫ –ø–æ–¥—Ä—è–¥.
    """
    user_text = (user_text or "").strip()
    if not user_text:
        return "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç —Å –ò–ù–ù, –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ –§–ò–û –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞."

    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∞–º –ø—Ä–∏—Å–ª–∞–ª —Å—Å—ã–ª–∫—É orginfo ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë –Ω–∞–ø—Ä—è–º—É—é
    url_match = ORGINFO_URL_RE.search(user_text)
    if url_match:
        url = url_match.group(0)
        return get_orginfo_from_url(url)

    # 1) –ü—Ä–æ—Å–∏–º GPT —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫–æ–≤—É—é —Ñ—Ä–∞–∑—É
    try:
        sys_prompt = (
            "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –∏—Å–∫–∞—Ç—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –ª–∏—Ü–∞ –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω–∞ –Ω–∞ —Å–∞–π—Ç–µ orginfo.uz. "
            "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç: —Ç–∞–º –º–æ–∂–µ—Ç –±—ã—Ç—å –ò–ù–ù, "
            "–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏, –§–ò–û –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞, –≥–æ—Ä–æ–¥ –∏ —Ç.–ø. "
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤–µ—Ä–Ω—É—Ç—å –ö–†–ê–¢–ö–£–Æ –ø–æ–∏—Å–∫–æ–≤—É—é —Ñ—Ä–∞–∑—É –¥–ª—è –ø–æ–∏—Å–∫–∞, "
            "–∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å –≤ Google: site:orginfo.uz <—Ñ—Ä–∞–∑–∞>. "
            "–ù–µ –æ–±—ä—è—Å–Ω—è–π, –Ω–µ –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–µ–≥–æ, –ø—Ä–æ—Å—Ç–æ –≤—ã–¥–∞–π –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –ø–æ–∏—Å–∫–∞."
        )
        completion = client.chat.completions.create(
            model=settings.openai_model,
            messages=[
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": user_text},
            ],
            max_tokens=40,
        )
        search_query = completion.choices[0].message.content.strip()
    except Exception as e:
        print("OpenAI error (orginfo_query build):", e)
        search_query = user_text

    # 2) –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏ —á–µ—Ä–µ–∑ SerpAPI
    urls = serpapi_search_orginfo(search_query, max_results=5)

    # 3) –ï—Å–ª–∏ SerpAPI –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à—ë–ª, –ø—Ä–æ–±—É–µ–º Google CSE (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)
    if not urls:
        urls = google_search_orginfo(search_query, max_results=5)

    if not urls:
        return (
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É —á–µ—Ä–µ–∑ orginfo.uz. "
            "–£—Ç–æ—á–Ω–∏—Ç–µ –ò–ù–ù –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏."
        )

    # 4) –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é
    cards: list[str] = []
    for url in urls:
        card = get_orginfo_from_url(url)
        cards.append(card)

    return "\n\n--------------------\n\n".join(cards)
